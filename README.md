# Time-Series Modeling of Physical Simulation Data

> This project focuses on modeling and forecasting time-dependent trajectories generated by physical simulations. The goal is to analyze noisy, high-dimensional time series representing physical systems and learn their temporal dynamics using machine learning approaches.

## Quick Start

Run a complete experiment with default settings:

```bash
python scripts/run_experiment.py
```

Or use the quick experiment script:

```bash
python scripts/quick_experiment.py
```

## Project Structure

```
data/
  raw/          - Raw simulation outputs or downloaded datasets
  processed/    - Cleaned and preprocessed time series

src/
  simulation/   - Code related to physical simulations or data generation
  features/     - Feature extraction and preprocessing utilities
  models/       - Machine learning models (autoencoders, LSTM, baselines)
  training/     - Training loops and optimization logic
  evaluation/   - Metrics computation and evaluation scripts
  utils/        - Shared utilities (seeding, logging, configuration)

experiments/    - Configuration files defining experiment parameters
tests/          - Unit tests for core components
reports/        - Figures, tables, and written analysis of results
scripts/        - Entry-point scripts for running experiments
```

## Running Experiments

### Complete Pipeline

Run the full experiment pipeline with a configuration file:

```bash
python scripts/run_experiment.py --config experiments/default_config.json
```

### Individual Steps

You can also run individual steps:

```bash
# Generate data
python scripts/generate_data.py

# Preprocess data
python scripts/preprocess_data.py

# Train models
python scripts/train_autoencoder.py
python scripts/train_lstm.py

# Evaluate models
python scripts/evaluate_all_models.py
```

### Custom Configuration

Create a custom configuration file in `experiments/` and run:

```bash
python scripts/run_experiment.py --config experiments/my_config.json
```

## Configuration

Experiment parameters are defined in JSON configuration files in the `experiments/` directory. The default configuration (`experiments/default_config.json`) includes:

- Data generation parameters (noise level, number of steps, etc.)
- Preprocessing options (features to include, normalization method)
- Training hyperparameters (learning rate, batch size, epochs)
- Evaluation settings (forecast horizons, metrics)

## Requirements

Install dependencies:

```bash
pip install -r requirements.txt
```

## Testing

Run unit tests:

```bash
pytest tests/ -v
```

## Results

Results are saved in the `reports/` directory:

- `baseline_results.json` - Baseline model performance
- `autoencoder_results.json` - Autoencoder training results
- `lstm_results.json` - LSTM training results
- `systematic_evaluation.json` - Comprehensive model comparison
- `robustness_study.json` - Robustness analysis across noise levels
- `failure_analysis.json` - Failure mode analysis
- `results_table.md` - Formatted results table
- `*.png` - Visualization plots

## Reproducibility

All experiments use fixed random seeds for reproducibility. The same configuration file will produce identical results when run multiple times.